{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "from jenkspy import jenks_breaks\n",
    "\n",
    "from covidcaremap.data import external_data_path, processed_data_path\n",
    "from covidcaremap.ihme import IHME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration that will be used in the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config = {\n",
    "    'dates': None, # Calculated below\n",
    "    'ihme_version': None, # Calculated below\n",
    "    'aggregations': {\n",
    "        'country': {\n",
    "            'per_capita_base': 1000000,\n",
    "            'breaks': { 'totals': None, 'per_capita': None } # Calculated below\n",
    "        },\n",
    "        'region': {\n",
    "            'per_capita_base': 100000,\n",
    "            'breaks': { 'totals': None, 'per_capita': None } # Calculated below\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a range of country/region boundaries to match up to IHME location names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gdf = gpd.read_file(external_data_path('us_states.geojson'), encoding='utf-8')\n",
    "countries_gdf = gpd.read_file(external_data_path('admin0.geojson'))\n",
    "spain_gdf = gpd.read_file('https://raw.githubusercontent.com/deldersveld/'\n",
    "                          'topojson/master/countries/spain/spain-comunidad.json')\n",
    "canary_islands_gdf = gpd.read_file('https://raw.githubusercontent.com/deldersveld/'\n",
    "                                   'topojson/master/countries/spain/canary-islands-province.json')\n",
    "italy_gdf = gpd.read_file('https://raw.githubusercontent.com/openpolis/'\n",
    "                          'geojson-italy/master/geojson/limits_IT_regions.geojson')\n",
    "admin1_gdf = gpd.read_file(external_data_path('admin1.geojson'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop_gdf = gpd.read_file(processed_data_path('us_states_with_pop.geojson'))\n",
    "worldpop_country_df = pd.read_csv(external_data_path('worldpop-country-pop-for-ihme-2020.csv'))\n",
    "worldpop_region_df = pd.read_csv(external_data_path('worldpop-region-pop-for-ihme-2020.csv'))\n",
    "worldpop_admin1_df = pd.read_csv(external_data_path('worldpop-admin1-2020.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldpop_admin1_df[worldpop_admin1_df['adm0_a3'] == 'CAN'] \\\n",
    "    .merge(admin1_gdf , on='adm1_code') \\\n",
    "    .drop(columns=['adm1_code']) \\\n",
    "    .rename(columns={'name': 'location_name'})[['adm0_a3_y','location_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Admin0 and Admin1 worldpop data to support new countries and regions added by IHME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldpop_admin1_processed_df = worldpop_admin1_df[['adm1_code', 'population']] \\\n",
    "    .merge(admin1_gdf[['adm1_code', 'name']] , on='adm1_code') \\\n",
    "    .drop(columns=['adm1_code']) \\\n",
    "    .rename(columns={'name': 'location_name'})\n",
    "\n",
    "worldpop_admin0_processed_df = worldpop_admin1_df.groupby('adm0_a3')['population'].sum() \\\n",
    "    .to_frame() \\\n",
    "    .merge(countries_gdf[['ADM0_A3', 'NAME']] , left_on='adm0_a3', right_on='ADM0_A3') \\\n",
    "    .drop(columns=['ADM0_A3']) \\\n",
    "    .rename(columns={'NAME': 'location_name'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the latest IHME projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_df, ihme_version = IHME.get_latest(include_version=True)\n",
    "ihme_config['ihme_version'] = ihme_version\n",
    "print('Model version: {}'.format(ihme_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns between IHME and the geospatial datasets so that they can be matched up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames for better matching\n",
    "italy_gdf = italy_gdf.replace({\n",
    "    '''Valle d'Aosta/Vallée d'Aoste''': '''Valle d'Aosta'''\n",
    "})\n",
    "\n",
    "# Rename regions to line up with GeoJSON values.\n",
    "ihme_df = ihme_df.replace({\n",
    "    # Spain regions\n",
    "    'Andalucia': 'Andalucía',\n",
    "    'Aragon': 'Aragón',\n",
    "    'Castile and Leon': 'Castilla y León',\n",
    "    'Catalonia': 'Cataluña',  \n",
    "    'Basque Country': 'País Vasco',\n",
    "    'Canary Islands': 'Islas Canarias',\n",
    "    'Valencian Community': 'Comunidad Valenciana',\n",
    "    \n",
    "    # Italy\n",
    "    'Provincia autonoma di Bolzano': 'Bozen',\n",
    "    'Provincia autonoma di Trento': 'Trento',\n",
    "    \n",
    "    # Germany\n",
    "    'Baden-Wurttemberg': 'Baden-Württemberg',\n",
    "    \n",
    "    # Canada\n",
    "    'Quebec': 'Québec' \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure we'll capture all the regions we want to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_regions = (\n",
    "    set(ihme_df['location_name'].values) - \n",
    "    set(state_gdf['NAME'].values) - \n",
    "    set(countries_gdf['ADMIN'].values) -\n",
    "    set(admin1_gdf['name_en'].values) -\n",
    "    set(admin1_gdf['name'].values) -\n",
    "    set(spain_gdf['NAME_1'].values) -\n",
    "    set(canary_islands_gdf['NAME_1'].values) -\n",
    "    set(italy_gdf['reg_name'].values)\n",
    ")\n",
    "\n",
    "regions_to_ignore = set([\n",
    "   'Other Counties, WA', \n",
    "   'Life Care Center, Kirkland, WA',\n",
    "   'King and Snohomish Counties (excluding Life Care Center), WA'\n",
    "])\n",
    "assert len(missing_regions - regions_to_ignore) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of location name to geometries and population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = [\n",
    "    (countries_gdf, 'ADMIN'),\n",
    "]\n",
    "\n",
    "country_pop_dfs = [\n",
    "    (worldpop_country_df, 'location_name', 'population'),\n",
    "    (worldpop_admin0_processed_df, 'location_name', 'population')\n",
    "]\n",
    "\n",
    "region_dfs = [\n",
    "    (state_gdf, 'NAME'),\n",
    "    (admin1_gdf, 'name_en'),\n",
    "    (admin1_gdf, 'name'),\n",
    "    (spain_gdf, 'NAME_1'),\n",
    "    (canary_islands_gdf, 'NAME_1'),\n",
    "    (italy_gdf, 'reg_name')\n",
    "]\n",
    "\n",
    "region_pop_dfs = [\n",
    "    (state_pop_gdf, 'State Name', 'Population'),\n",
    "    (worldpop_region_df, 'location_name', 'population'),\n",
    "    (worldpop_admin1_processed_df, 'location_name', 'population')\n",
    "]\n",
    "\n",
    "def get_geoms_by_name(dfs):\n",
    "    result = {}\n",
    "    \n",
    "    for df, name_col in dfs:\n",
    "        for _, feature in df.iterrows():\n",
    "            name = feature[name_col]\n",
    "            if name is not None:\n",
    "                if name not in result:\n",
    "                    result[name] = feature['geometry']\n",
    "    return result\n",
    "\n",
    "def get_pop_by_name(dfs):\n",
    "    result = {}\n",
    "    \n",
    "    for df, name_col, pop_col in dfs:\n",
    "        for _, row in df.iterrows():\n",
    "            name = row[name_col]\n",
    "            if name is not None:\n",
    "                if name not in result:\n",
    "                    result[name] = row[pop_col]\n",
    "    return result\n",
    "\n",
    "country_geom_by_name = get_geoms_by_name(country_dfs)\n",
    "country_pop_by_name = get_pop_by_name(country_pop_dfs)\n",
    "region_geom_by_name = get_geoms_by_name(region_dfs)  \n",
    "region_pop_by_name = get_pop_by_name(region_pop_dfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods that generate the IHME GeoJSON for each of our region groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_cols = [\n",
    "    'allbed_mean', \n",
    "    'allbed_lower',\n",
    "    'allbed_upper', \n",
    "    'ICUbed_mean', \n",
    "    'ICUbed_lower', \n",
    "    'ICUbed_upper',\n",
    "    'InvVen_mean', \n",
    "    'InvVen_lower', \n",
    "    'InvVen_upper', \n",
    "    'deaths_mean',\n",
    "    'deaths_lower', \n",
    "    'deaths_upper', \n",
    "    'admis_mean', \n",
    "    'admis_lower',\n",
    "    'admis_upper', \n",
    "    'newICU_mean', \n",
    "    'newICU_lower', \n",
    "    'newICU_upper',\n",
    "    'totdea_mean', \n",
    "    'totdea_lower', \n",
    "    'totdea_upper', \n",
    "    'bedover_mean',\n",
    "    'bedover_lower', \n",
    "    'bedover_upper', \n",
    "    'icuover_mean', \n",
    "    'icuover_lower',\n",
    "    'icuover_upper']\n",
    "\n",
    "def gather_features_by_name(geoms_by_name, pop_by_name, df):\n",
    "    dates = set([])\n",
    "    props_by_name = defaultdict(dict)\n",
    "    for _, row in df.iterrows():\n",
    "        name = row['location_name']\n",
    "        date = row['date']\n",
    "        dates.add(date)\n",
    "        for col in value_cols:\n",
    "            props_by_name[name]['{}_{}'.format(date, col)] = row[col]\n",
    "    \n",
    "    features = []\n",
    "    names_found = []\n",
    "    names_not_found = []\n",
    "    for name in props_by_name:\n",
    "        if name in geoms_by_name:\n",
    "            geom = geoms_by_name[name]\n",
    "            pop = pop_by_name[name]\n",
    "            props = { 'location_name': name, 'population': pop }\n",
    "            for k, v in props_by_name[name].items():\n",
    "                props[k] = v\n",
    "            features.append({\n",
    "                'type': 'Feature',\n",
    "                'geometry': mapping(geom),\n",
    "                'properties': props\n",
    "            })\n",
    "            names_found.append(name)\n",
    "        else:\n",
    "            names_not_found.append(name)\n",
    "    return features, dates, set(names_found), set(names_not_found)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for generating breaks that will be used to color the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = set(map(lambda x: x.split('_')[0], value_cols))\n",
    "levels = set(map(lambda x: x.split('_')[1], value_cols))\n",
    "\n",
    "def get_prop_values(features, per_capita_base=None):\n",
    "    result = {}\n",
    "    for m in metrics:\n",
    "        result[m] = {}\n",
    "        for l in levels:\n",
    "            result[m][l] = []\n",
    "\n",
    "    for feat in features:\n",
    "        if per_capita_base is not None:\n",
    "            pop = feat['properties']['population']\n",
    "            denom = pop / per_capita_base\n",
    "        else:\n",
    "             denom = 1\n",
    "                \n",
    "        for k, v in feat['properties'].items():\n",
    "            if k not in ['location_name', 'population']:\n",
    "                _, metric, level = k.split('_')\n",
    "                result[metric][level].append(v / denom)\n",
    "                \n",
    "    return dict(result)\n",
    "\n",
    "def compute_breaks(features, per_capita_base=None):\n",
    "    result = {}\n",
    "    for m in metrics:\n",
    "        result[m] = {}\n",
    "        for l in levels:\n",
    "            result[m][l] = None\n",
    "            \n",
    "    prop_values = get_prop_values(features, per_capita_base)\n",
    "    for m in prop_values:\n",
    "        for l in prop_values[m]:\n",
    "            result[m][l] = jenks_breaks(prop_values[m][l], nb_class=6)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for creating GeoJSON and breaks files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(geom_by_name, pop_by_name, agg_id):\n",
    "    # GeoJSON\n",
    "    features, dates, names_found, names_not_found = gather_features_by_name(\n",
    "        geom_by_name, pop_by_name, ihme_df\n",
    "    )\n",
    "    \n",
    "    feature_collection = {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Set breaks\n",
    "    ihme_config['aggregations'][agg_id]['breaks']['totals'] = compute_breaks(features)\n",
    "    ihme_config['aggregations'][agg_id]['breaks']['per_capita'] = compute_breaks(\n",
    "        features, ihme_config['aggregations'][agg_id]['per_capita_base']\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        feature_collection, \n",
    "        processed_data_path('ihme-{}-data.geojson'.format(agg_id)),\n",
    "        dates, \n",
    "        names_found, \n",
    "        names_not_found\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Countries\n",
    "(\n",
    "    country_feature_collection,\n",
    "    country_geojson_path,\n",
    "    country_dates, \n",
    "    country_names_found, \n",
    "    country_names_not_found\n",
    ") = create_data(country_geom_by_name, country_pop_by_name, 'country')\n",
    "\n",
    "# For Regions\n",
    "(\n",
    "    region_feature_collection,\n",
    "    region_geojson_path, \n",
    "    region_dates, \n",
    "    region_names_found, \n",
    "    region_names_not_found\n",
    ") = create_data(region_geom_by_name, region_pop_by_name, 'region')\n",
    "\n",
    "# Set the dates into the config for visualization.\n",
    "ihme_config['dates'] = sorted(list(country_dates.union(region_dates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform final check that we didn't miss any regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last check that we didn't miss any regions.\n",
    "assert len(\n",
    "    (\n",
    "        region_names_not_found.union(country_names_not_found) - \n",
    "        region_names_found.union(country_names_found)\n",
    "    ) - regions_to_ignore\n",
    ") == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(country_geojson_path, 'w') as f:\n",
    "    f.write(json.dumps(country_feature_collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(region_geojson_path, 'w') as f:\n",
    "    f.write(json.dumps(region_feature_collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processed_data_path('ihme-config.json'), 'w') as f:\n",
    "    f.write(json.dumps(ihme_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['country']['breaks']['per_capita']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['region']['breaks']['per_capita']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['region']['breaks']['totals']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
